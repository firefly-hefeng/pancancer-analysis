#!/usr/bin/env python3
import pandas as pd
from pathlib import Path
from ftplib import FTP, error_perm
import logging
from tqdm import tqdm
import socket
import time

# ==================== é…ç½®åŒºåŸŸ ====================
# è¾“å…¥ï¼šmerged_summary.csvæ–‡ä»¶è·¯å¾„
MERGED_CSV_PATH = Path("/mnt/public7/pancancercol/meta_analysis/hefeng_metadata/meta_data_collect/meta1/arrayexpress/processed_data/merged_summary.csv")

# è¾“å‡ºï¼šå…ƒæ–‡ä»¶å­˜å‚¨æ ¹ç›®å½•
OUTPUT_ROOT = Path("/mnt/public7/pancancercol/meta_analysis/hefeng_metadata/meta_data_collect/meta1/arrayexpress/metadata_files_batch_ftp")

# FTPæœåŠ¡å™¨é…ç½®
FTP_HOST = "ftp.ebi.ac.uk"
FTP_USER = "anonymous"
FTP_PASS = ""

# æ—¥å¿—è®¾ç½®
LOG_LEVEL = logging.INFO
# =================================================

# åˆ›å»ºè¾“å‡ºç›®å½•
OUTPUT_ROOT.mkdir(parents=True, exist_ok=True)

# é…ç½®æ—¥å¿—
log_file = OUTPUT_ROOT / "download_batch.log"
logging.basicConfig(
    level=LOG_LEVEL,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_file, encoding='utf-8'),
        logging.StreamHandler()
    ]
)

def build_ftp_path(accession: str) -> str:
    """æ ¹æ®Accessionæ„å»ºFTPè·¯å¾„"""
    acc_parts = accession.split('-')
    if len(acc_parts) < 3:
        raise ValueError(f"Invalid accession format: {accession}")
    
    prefix = '-'.join(acc_parts[:-1])  # "E-MTAB"
    number = acc_parts[-1]             # "6149"
    suffix = number[-3:] if len(number) >= 3 else number  # "149"
    
    return f"biostudies/fire/{prefix}-/{suffix}/{accession}/Files"

def download_metadata_ftp(accession: str, local_dir: Path, max_retries: int = 3) -> tuple:
    """
    é€šè¿‡FTPä¸‹è½½æŒ‡å®šAccessionçš„IDFå’ŒSDRFæ–‡ä»¶
    
    Returns:
        tuple: (success: bool, downloaded_files: list, error_msg: str)
    """
    local_dir.mkdir(parents=True, exist_ok=True)
    downloaded_files = []
    ftp = None
    
    for attempt in range(1, max_retries + 1):
        try:
            # 1. å»ºç«‹FTPè¿æ¥ï¼ˆè¢«åŠ¨æ¨¡å¼ï¼‰
            ftp = FTP()
            ftp.connect(host=FTP_HOST, port=21, timeout=60)
            ftp.login(user=FTP_USER, passwd=FTP_PASS)
            ftp.set_pasv(True)  # å¯ç”¨è¢«åŠ¨æ¨¡å¼
            
            # 2. æ„å»ºå¹¶è¿›å…¥FTPè·¯å¾„
            ftp_path = build_ftp_path(accession)
            try:
                ftp.cwd(ftp_path)
            except error_perm:
                return False, [], f"Directory not found: {ftp_path}"
            
            # 3. ç­›é€‰ç›®æ ‡æ–‡ä»¶
            all_files = ftp.nlst()
            target_files = [f for f in all_files if f.endswith(('.idf.txt', '.sdrf.txt'))]
            
            if not target_files:
                return False, [], f"No MAGE-TAB files found in {ftp_path}"
            
            # 4. ä¸‹è½½æ–‡ä»¶
            for filename in target_files:
                local_path = local_dir / filename
                
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼ˆé¿å…é‡å¤ä¸‹è½½ï¼‰
                if local_path.exists():
                    logging.debug(f"  â†’ {filename} already exists, skipping")
                    downloaded_files.append(str(local_path))
                    continue
                
                # ä½¿ç”¨äºŒè¿›åˆ¶æ¨¡å¼ä¸‹è½½
                with open(local_path, 'wb') as f:
                    ftp.retrbinary(f'RETR {filename}', f.write)
                
                file_size = local_path.stat().st_size
                downloaded_files.append(str(local_path))
                logging.info(f"  âœ“ {filename} ({file_size:,} bytes)")
            
            # 5. æˆåŠŸä¸‹è½½å¹¶æ–­å¼€è¿æ¥
            ftp.quit()
            return True, downloaded_files, None
            
        except socket.timeout:
            wait_time = attempt * 10
            logging.warning(f"  Timeout on attempt {attempt}/{max_retries}, waiting {wait_time}s...")
            time.sleep(wait_time)
            
        except error_perm as e:
            error_msg = f"FTP permission error: {e}"
            logging.error(f"  {error_msg}")
            return False, [], error_msg
            
        except Exception as e:
            logging.error(f"  Unexpected error on attempt {attempt}: {e}")
            
        finally:
            if ftp:
                try:
                    ftp.quit()
                except:
                    pass
    
    # æ‰€æœ‰é‡è¯•å¤±è´¥
    return False, [], f"Failed after {max_retries} attempts"

def main():
    logging.info("="*80)
    logging.info("ArrayExpress æ‰¹é‡FTPä¸‹è½½å·¥å…·")
    logging.info(f"è¾“å…¥æ–‡ä»¶: {MERGED_CSV_PATH}")
    logging.info(f"è¾“å‡ºç›®å½•: {OUTPUT_ROOT}")
    logging.info("="*80)
    
    # 1. è¯»å–merged_summary.csv
    if not MERGED_CSV_PATH.exists():
        logging.error(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {MERGED_CSV_PATH}")
        return
    
    try:
        df = pd.read_csv(MERGED_CSV_PATH)
        accessions = df['Accession'].dropna().unique().tolist()
        logging.info(f"ğŸ“Š ä»merged_summary.csvä¸­åŠ è½½äº† {len(accessions)} ä¸ªAccession")
    except Exception as e:
        logging.error(f"âŒ è¯»å–CSVæ–‡ä»¶å¤±è´¥: {e}")
        return
    
    # 2. åˆå§‹åŒ–ç»Ÿè®¡
    results = {
        'success': [],
        'failed': [],
        'notfound': []
    }
    
    # 3. æ‰¹é‡ä¸‹è½½
    logging.info("\nğŸš€ å¼€å§‹æ‰¹é‡ä¸‹è½½å…ƒæ•°æ®æ–‡ä»¶...")
    logging.info("(ä»…ä¸‹è½½ .idf.txt å’Œ .sdrf.txt)\n")
    
    for accession in tqdm(accessions, desc="æ€»ä½“è¿›åº¦", unit="exp"):
        local_dir = OUTPUT_ROOT / accession
        
        success, files, error = download_metadata_ftp(accession, local_dir)
        
        if success:
            results['success'].append({
                'Accession': accession,
                'Files_Downloaded': len(files),
                'File_List': ', '.join([Path(f).name for f in files])
            })
        elif "No MAGE-TAB files found" in error:
            results['notfound'].append(accession)
            logging.warning(f"âš ï¸  Accession {accession}: {error}")
        else:
            results['failed'].append({
                'Accession': accession,
                'Error': error
            })
            logging.error(f"âœ— Accession {accession}: {error}")
    
    # 4. ç”ŸæˆæŠ¥å‘Š
    logging.info("\n" + "="*80)
    logging.info("ç”Ÿæˆä¸‹è½½æŠ¥å‘Š...")
    
    # æˆåŠŸæŠ¥å‘Š
    if results['success']:
        success_df = pd.DataFrame(results['success'])
        success_df.to_csv(OUTPUT_ROOT / 'download_success_report.csv', index=False)
        logging.info(f"  âœ“ æˆåŠŸæŠ¥å‘Š: {len(success_df)} æ¡è®°å½•")
    
    # å¤±è´¥æŠ¥å‘Š
    if results['failed']:
        failed_df = pd.DataFrame(results['failed'])
        failed_df.to_csv(OUTPUT_ROOT / 'download_failed_report.csv', index=False)
        logging.info(f"  âœ— å¤±è´¥æŠ¥å‘Š: {len(failed_df)} æ¡è®°å½•")
    
    # æœªæ‰¾åˆ°æŠ¥å‘Š
    if results['notfound']:
        notfound_df = pd.DataFrame({'Accession': results['notfound']})
        notfound_df.to_csv(OUTPUT_ROOT / 'download_notfound_report.csv', index=False)
        logging.info(f"  ? æœªæ‰¾åˆ°æŠ¥å‘Š: {len(notfound_df)} æ¡è®°å½•")
    
    # 5. æ€»ç»“
    total = len(accessions)
    success_count = len(results['success'])
    failed_count = len(results['failed'])
    notfound_count = len(results['notfound'])
    
    logging.info("\n" + "="*80)
    logging.info("ğŸ¯ ä¸‹è½½ä»»åŠ¡å®Œæˆæ€»ç»“")
    logging.info("="*80)
    logging.info(f"ğŸ“¦ æ€»è®¡å¤„ç†: {total} ä¸ªå®éªŒ")
    logging.info(f"âœ… ä¸‹è½½æˆåŠŸ: {success_count} ({success_count/total*100:.1f}%)")
    logging.info(f"âŒ ä¸‹è½½å¤±è´¥: {failed_count} ({failed_count/total*100:.1f}%)")
    logging.info(f"âš ï¸  æ–‡ä»¶ç¼ºå¤±: {notfound_count} ({notfound_count/total*100:.1f}%)")
    logging.info(f"\nğŸ“‚ æ‰€æœ‰æ–‡ä»¶å­˜å‚¨åœ¨: {OUTPUT_ROOT}")
    logging.info(f"ğŸ“ è¯¦ç»†æ—¥å¿—è¯·æŸ¥çœ‹: {log_file}")
    logging.info("="*80)

if __name__ == "__main__":
    main()